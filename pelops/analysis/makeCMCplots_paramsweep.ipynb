{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pprint\n",
    "import pickle\n",
    "import collections\n",
    "import multiprocessing\n",
    "\n",
    "pelops_dir = os.path.abspath('../..')\n",
    "sys.path.insert(0, pelops_dir)\n",
    "\n",
    "from pelops.datasets.featuredataset import FeatureDataset\n",
    "from pelops.experiment_api.experiment import ExperimentGenerator\n",
    "from pelops.analysis import analysis\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set experiment constants\n",
    "\n",
    "ITEMS_PER_CAMERA = 10\n",
    "Y_RANDOM=1024\n",
    "CAMERAS=2\n",
    "DROPPED=0\n",
    "CMC_CNT=100\n",
    "EXPERIMENTS=400\n",
    "\n",
    "# Set data constants\n",
    "DATA_ROOT = os.path.expanduser('~/Data')\n",
    "OUT_DIR = os.path.expanduser('~/Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scan for and locate feature datasets\n",
    "\n",
    "files_by_network = collections.defaultdict(dict)\n",
    "files_by_dataset = collections.defaultdict(dict)\n",
    "file_pattern = re.compile('^(?P<key>.+?)_\\d+px_[A-Za-z]+\\.hdf5', re.S | re.I)\n",
    "\n",
    "for root, sub_dirs, file_names in os.walk(DATA_ROOT):\n",
    "    full_names = [os.path.join(root, fn) for fn in file_names if fn.endswith('.hdf5')]\n",
    "    if len(full_names) > 0:\n",
    "        dataset_name = os.path.basename(root)\n",
    "        for file_name in full_names:\n",
    "            mch = re.search(file_pattern, os.path.basename(file_name))\n",
    "            if mch is None:\n",
    "                print('ERROR: {}'.format(file_name))\n",
    "            network_name = mch.group('key')\n",
    "            files_by_network[network_name][dataset_name] = file_name\n",
    "            files_by_dataset[dataset_name][network_name] = file_name\n",
    "            \n",
    "formatter = lambda d, s: '{}:\\n{}'.format(s, pprint.pformat({k: [h for h in v] for k, v in d.items()}))\n",
    "print(formatter(files_by_network, 'Files By Network'))\n",
    "print(formatter(files_by_dataset, 'Files By Dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define experiment behavior and processing output\n",
    "\n",
    "def run_experiment(args):\n",
    "    feature_file, title, output_file = args\n",
    "    print(title)\n",
    "    \n",
    "    # Require output dir\n",
    "    out_dir = os.path.dirname(output_file)\n",
    "    if not os.path.isdir(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    \n",
    "    # Run experiment\n",
    "    features = FeatureDataset(feature_file)\n",
    "    experiment_gen = ExperimentGenerator(features, CAMERAS, ITEMS_PER_CAMERA, DROPPED, Y_RANDOM)\n",
    "    experiment_hldr = analysis.repeat_pre_cmc(features, experiment_gen, NUMCMC=CMC_CNT, EXPPERCMC=EXPERIMENTS)\n",
    "    stats, gdata = analysis.make_cmc_stats(experiment_hldr, ITEMS_PER_CAMERA)\n",
    "    \n",
    "    # Save raw experiment results\n",
    "    meta = {\n",
    "        'feature_file': feature_file,\n",
    "        'title': title,\n",
    "        'output_file': output_file,\n",
    "        'stats': stats,\n",
    "        'gdata': gdata,\n",
    "        'ITEMS_PER_CAMERA': ITEMS_PER_CAMERA,\n",
    "        'Y_RANDOM': Y_RANDOM,\n",
    "        'CAMERAS': CAMERAS,\n",
    "        'DROPPED': DROPPED,\n",
    "        'CMC_CNT': CMC_CNT,\n",
    "        'EXPERIMENTS': EXPERIMENTS\n",
    "    }\n",
    "    with open(output_file + '.pkl', 'wb') as out_hdl:\n",
    "        pickle.dump(meta, out_hdl)\n",
    "\n",
    "    # Plot experiment results\n",
    "    figure = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(gdata.transpose())\n",
    "    plt.title('{}\\n({} CMC curves with {} experiments / curve)'.format(title, CMC_CNT, EXPERIMENTS))\n",
    "    ax.legend(('-stddev','avg','+stddev'), bbox_to_anchor=(1, -0.05), fancybox=True, shadow=True, ncol=5)\n",
    "    plt.savefig(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run all the experiments\n",
    "\n",
    "def get_jobs(index):\n",
    "    cnt = 0\n",
    "    for training_set in index:\n",
    "        for test_set in index[training_set]:\n",
    "            feature_file = index[training_set][test_set]\n",
    "            title = \"Processing {} using {} trained network\".format(test_set, training_set)\n",
    "            out_file = \"{}/{}_{}\".format(OUT_DIR, test_set, training_set)\n",
    "            yield feature_file, title, out_file\n",
    "\n",
    "\n",
    "pool = multiprocessing.Pool(4)\n",
    "try:\n",
    "    pool.map(run_experiment, get_jobs(files_by_network))\n",
    "finally:\n",
    "    pool.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
